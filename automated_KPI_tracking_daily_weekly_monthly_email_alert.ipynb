{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated KPI email alerts for Business Users\n",
    "\n",
    "## KPIs\n",
    "\n",
    "- Total Number of Orders\n",
    "- Gross Revenue\n",
    "- Discount\n",
    "- Net Revenue\n",
    "- Average Delivery Time of Orders\n",
    "- Average Preparation Time of Orders\n",
    "- Total Users\n",
    "- New Users in the time period\n",
    "- User Retention in the time period\n",
    "\n",
    "\n",
    "### - Percentage Change over the time period\n",
    "\n",
    "## Data Sources\n",
    "\n",
    "- Database - Mysql\n",
    "- Cloud - Google Cloud Storage\n",
    "- Data Access - BigQuery MySQL\n",
    "\n",
    "## Alerting Module\n",
    "\n",
    "- Python - email, Request, and others\n",
    "- Gmail alert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BACKGROUND\n",
    "\n",
    "### The Pulse of Progress: Automating KPI Alerts for a Data-Driven Business\n",
    "\n",
    "In today's dynamic business landscape, staying ahead of the curve isn't just about tracking numbers; it's about understanding their implications in real-time and acting decisively. Simply monitoring dashboards isn't enough. The true value lies in proactive insights, delivered precisely when they matter most. This is where the magic of automated KPI alerts comes in.\n",
    "\n",
    "Key Performace Indicators (KPI) are the vital signs of a business's operational health, reflecting it's ability to navigate market fluctuations and achieve strategic objectives. Automated KPI alerts act as early warning systems, signaling potential headwinds or tailwinds as they begin to materialize.\n",
    "\n",
    "Automated alerts empower us to move beyond reactive analysis to proactive risk management and opportunity identification. They help us connect micro-level operational data with macro-level economic trends, leading to more informed and timely strategic decisions\n",
    "\n",
    "Some Key points are :\n",
    "\n",
    "The specific KPI and its current value.\n",
    "The magnitude and direction of the change (e.g., a 15% drop in weekly sales).\n",
    "Comparison to previous periods (daily, weekly, monthly averages).\n",
    "Potential contributing factors (if integrated with other data sources).\n",
    "Links to relevant dashboards or reports for deeper investigation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 774,
     "status": "ok",
     "timestamp": 1653907671097,
     "user": {
      "displayName": "Pallavi Krishna",
      "userId": "10169624835644536579"
     },
     "user_tz": -240
    },
    "id": "zKA_jKoTzf7d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "from datetime import timedelta\n",
    "import datetime\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import base64\n",
    "\n",
    "# Gmail API utils\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.text import MIMEText\n",
    "from googleapiclient.discovery import build\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.base import MIMEBase\n",
    "from email import encoders\n",
    "\n",
    "from google.auth.transport.requests import Request\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "\n",
    "# Write excel files with KPIs\n",
    "\n",
    "from pandas import ExcelWriter\n",
    "from pandas import ExcelFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18720,
     "status": "ok",
     "timestamp": 1653907689814,
     "user": {
      "displayName": "Pallavi Krishna",
      "userId": "10169624835644536579"
     },
     "user_tz": -240
    },
    "id": "vH1DKYtv2Qto",
    "outputId": "ea6f12b8-cbcf-442e-c618-a50d431a5ebf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authenticated\n"
     ]
    }
   ],
   "source": [
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "print('Authenticated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 538,
     "status": "ok",
     "timestamp": 1653907690350,
     "user": {
      "displayName": "Pallavi Krishna",
      "userId": "10169624835644536579"
     },
     "user_tz": -240
    },
    "id": "fhPInYWV2lKE"
   },
   "outputs": [],
   "source": [
    "project_id = \"mixing-testnet\"\n",
    "from google.cloud import bigquery\n",
    "client = bigquery.Client(project=project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 295,
     "status": "ok",
     "timestamp": 1653907736924,
     "user": {
      "displayName": "Pallavi Krishna",
      "userId": "10169624835644536579"
     },
     "user_tz": -240
    },
    "id": "tZTXxAjjTheS"
   },
   "outputs": [],
   "source": [
    "def errors(error,error_name,code,platform):\n",
    "    \n",
    "    \"\"\"Write the error into an error file\"\"\"\n",
    "    \n",
    "    today = pd.to_datetime(date.today())\n",
    "    current_time = today.strftime(\"%H:%M:%S\")\n",
    "    today=today.strftime('%Y-%m-%d')\n",
    "    error=str(error)\n",
    "    df=pd.DataFrame([[code,platform,error,error_name,today,current_time]],columns=['Code','Platform','Error','Error_Name','run_date','run_time'])\n",
    "    #target_table = \"mixing-testnet.10_min_Delivery_error.Error_logs_shipsy_order\"\n",
    "    target_table = \"10_min_Delivery_error.Error_logs_daily_alert\"\n",
    "    #credential_file = (\"mixing-testnet-4df1b518f6ef.json\")\n",
    "    project_id = \"mixing-testnet\"\n",
    "    #credential = Credentials.from_service_account_file(credential_file)\n",
    "    # Location for BQ job, it needs to match with destination table location\n",
    "    # Save Pandas dataframe to BQ\n",
    "#     df['run_date']=df['run_date'].astype(str)\n",
    "#    df.to_gbq(target_table,project_id=project_id,progress_bar=True,if_exists='replace', table_schema=None,credentials=credential)\n",
    "    df.to_gbq(target_table, project_id=project_id, progress_bar=True,if_exists='append', table_schema=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 10286,
     "status": "ok",
     "timestamp": 1653907748700,
     "user": {
      "displayName": "Pallavi Krishna",
      "userId": "10169624835644536579"
     },
     "user_tz": -240
    },
    "id": "t62mJCWg2xaN"
   },
   "outputs": [],
   "source": [
    "# Data extraction from Mysql, BigQuery\n",
    "\n",
    "try:\n",
    "  query_send = '''\n",
    "  SELECT o.Order_date, o.Order_time, o.Order_id, o.Outlet_name, o.Order_status, o.Order_source, o.Total_discount, o.Total_tax, o.Subtotal, o.Total_charge, \n",
    "  o.Merchant_offer_code, o.Customer_mobile, o.Customer_name, o.Loyalty_amount, o.Customer_email, o.Revenue, os.Id, os.State_current, os.Prepration_time,\n",
    "  d.Rider_Name, d.Single_Run, d.Order_Time, d.Reassigned_Rider, \n",
    "  d.order_to_makeline, d.makeline_to_order_assign, d.Order_Assign_to_bike, d.store_to_gate_time,\n",
    "  d.gate_to_delivery, d.delivery_to_store, d.makeline_Delivery_final, d.slot_time, d.overall_delivery_category\n",
    "  FROM `mixing-testnet.10min_Orderwise.stg_10min_orders` o \n",
    "  INNER JOIN `mixing-testnet.10min_Orderwise.stg_10min_order_status` os \n",
    "  ON (o.Order_id = os.Id)\n",
    "  INNER JOIN `mixing-testnet.10min_Delivery.stg_10min_delivery_reports` d \n",
    "  ON (o.Order_id = d.Order_Id)\n",
    "  WHERE o.Merchant_offer_code != 'SACHIN' AND o.Order_status = 'DELIVERED' '''\n",
    "  df_merged = client.query(query_send).to_dataframe()\n",
    "except Exception as e:\n",
    "  errors(e, 'big_query_error', 'Daily_Alert', 'voosh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 285,
     "status": "ok",
     "timestamp": 1653907784718,
     "user": {
      "displayName": "Pallavi Krishna",
      "userId": "10169624835644536579"
     },
     "user_tz": -240
    },
    "id": "6D-yrDL15wLz"
   },
   "outputs": [],
   "source": [
    "#initialise data\n",
    "\n",
    "#Set Flags\n",
    "\n",
    "Data_Exists_Daily = False\n",
    "Data_Exists_Weekly = False\n",
    "Data_Exists_Monthly = False\n",
    "\n",
    "#Week Month Flags\n",
    "Is_Month_Start = False\n",
    "Is_Week_Start = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 273,
     "status": "ok",
     "timestamp": 1653907791157,
     "user": {
      "displayName": "Pallavi Krishna",
      "userId": "10169624835644536579"
     },
     "user_tz": -240
    },
    "id": "_YQgiTeg_PYM",
    "outputId": "07a7c8a6-632b-458c-b014-d69806ee1150"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2022-05-30 00:00:00'),\n",
       " Timestamp('2022-05-29 00:00:00'),\n",
       " Timestamp('2022-05-28 00:00:00'))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if week start / month start\n",
    "\n",
    "T_Date = pd.to_datetime(date.today())\n",
    "T_1_Date =  pd.to_datetime(date.today() - timedelta(days = 1))\n",
    "T_2_Date = pd.to_datetime(date.today() - timedelta(days = 2))\n",
    "if (T_Date.is_month_start)|(T_1_Date.is_month_start)|(T_2_Date.is_month_start):\n",
    "  Is_Month_Start = True\n",
    "  month_1 = T_Date.month -1\n",
    "  month_2 = T_Date.month -2 \n",
    "if (T_Date.day_name()=='Monday'):\n",
    "  Is_Week_Start = True \n",
    "  week_1 = T_Date.week -1\n",
    "  week_2 = T_Date.week -2 \n",
    "\n",
    "T_Date,T_1_Date,T_2_Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 296,
     "status": "ok",
     "timestamp": 1653907807316,
     "user": {
      "displayName": "Pallavi Krishna",
      "userId": "10169624835644536579"
     },
     "user_tz": -240
    },
    "id": "ZgYkNbDuIJjd"
   },
   "outputs": [],
   "source": [
    "#Initial Data Prep\n",
    "\n",
    "def convert_to_minutes(x): #11:33:23 #convert_to_minutes('00:02:30')\n",
    "  return round((float(x.split(':')[0])*60) + (float(x.split(':')[1])*1) + (float(x.split(':')[2])/60),2)\n",
    "\n",
    "try:\n",
    "  df_merged['Prep_Time'] = df_merged['Prepration_time'].fillna('00:00:00').apply(convert_to_minutes)\n",
    "  df_merged['MFR_Marked'] = (df_merged['Prep_Time']==0) \n",
    "  df_merged['Year'] = pd.to_datetime(df_merged['Order_date']).dt.year\n",
    "  df_merged['Month'] = pd.to_datetime(df_merged['Order_date']).dt.month\n",
    "  df_merged['Week'] = pd.to_datetime(df_merged['Order_date']).dt.isocalendar().week\n",
    "#store_name = df_merged['Outlet_name'].unique()\n",
    "except Exception as e:\n",
    "  errors(e, 'Initial_Data_Prep', 'Daily_Alert', 'voosh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 313,
     "status": "ok",
     "timestamp": 1653907816073,
     "user": {
      "displayName": "Pallavi Krishna",
      "userId": "10169624835644536579"
     },
     "user_tz": -240
    },
    "id": "34hpbK-QND1y",
    "outputId": "d8982f4a-9086-4759-e648-457c078f92f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 23\n"
     ]
    }
   ],
   "source": [
    "#Daily Values\n",
    "\n",
    "try:\n",
    "  T_1 = (date.today() - timedelta(days = 1)).strftime(\"%Y-%m-%d\") #yesterday \n",
    "  T_2 = (date.today() - timedelta(days = 2)).strftime(\"%Y-%m-%d\") #day before yesterday\n",
    "  #print(T_1,T_2)\n",
    "  df_T_1 = df_merged[df_merged['Order_date']==T_1]\n",
    "  df_T_2 = df_merged[df_merged['Order_date']==T_2]\n",
    "  print(len(df_T_1),len(df_T_2))\n",
    "  #daily_alert =pd.DataFrame(columns=['(T-2)','Yesterday(T-1)'],index=['Total Orders','Gross Revenue $', \n",
    "  daily_alert =pd.DataFrame(columns=[T_2,T_1],index=['Total Orders','Gross Revenue $', \n",
    "                                                                                          'Discount $','Net Revenue $', 'Avg Delivery Time',\n",
    "                                                                                          'Avg Prep time', 'MFR%','New Users', 'Old Users'])\n",
    "  if len(df_T_1) !=0 and len(df_T_2) !=0:\n",
    "    #Prepare T-1 Alert\n",
    "    #print('here')\n",
    "    daily_alert.loc['Total Orders',T_1] = len(df_T_1)\n",
    "    daily_alert.loc['Gross Revenue $',T_1] = df_T_1['Revenue'].sum() + df_T_1['Total_discount'].sum()\n",
    "    daily_alert.loc['Discount $',T_1] = df_T_1['Total_discount'].sum()\n",
    "    daily_alert.loc['Net Revenue $',T_1] = df_T_1['Revenue'].sum()\n",
    "    daily_alert.loc['Avg Delivery Time',T_1] = round(df_T_1[df_T_1['makeline_Delivery_final']<=100]['makeline_Delivery_final'].mean(),2)\n",
    "    daily_alert.loc['Avg Prep time',T_1] = round(df_T_1[df_T_1['Prep_Time']!=0]['Prep_Time'].mean(),2)\n",
    "    daily_alert.loc['MFR%',T_1] = round((len(df_T_1[~df_T_1['MFR_Marked']])/(len(df_T_1)))*100,2)\n",
    "    daily_alert.loc['Total Users',T_1] = len(set(df_T_1['Customer_mobile']))\n",
    "    daily_alert.loc['New Users',T_1] = len(set(df_T_1['Customer_mobile'])) - len(set(df_merged[df_merged['Order_date']!=T_1]['Customer_mobile']).intersection(set(df_T_1['Customer_mobile'])))\n",
    "    daily_alert.loc['Old Users',T_1] = len(set(df_merged[df_merged['Order_date']!=T_1]['Customer_mobile']).intersection(set(df_T_1['Customer_mobile'])))\n",
    "\n",
    "    #Prepare T-2 Alert\n",
    "    daily_alert.loc['Total Orders',T_2] = len(df_T_2)\n",
    "    daily_alert.loc['Gross Revenue $',T_2] = df_T_2['Revenue'].sum() + df_T_2['Total_discount'].sum()\n",
    "    daily_alert.loc['Discount $',T_2] = df_T_2['Total_discount'].sum()\n",
    "    daily_alert.loc['Net Revenue $',T_2] = df_T_2['Revenue'].sum()\n",
    "    daily_alert.loc['Avg Delivery Time',T_2] = round(df_T_2[df_T_2['makeline_Delivery_final']<=100]['makeline_Delivery_final'].mean(),2)\n",
    "    daily_alert.loc['Avg Prep time',T_2] = round(df_T_2[df_T_2['Prep_Time']!=0]['Prep_Time'].mean(),2)\n",
    "    daily_alert.loc['MFR%',T_2] = round((len(df_T_2[~df_T_2['MFR_Marked']])/(len(df_T_2)))*100,2)\n",
    "    daily_alert.loc['Total Users',T_2] = len(set(df_T_2['Customer_mobile']))\n",
    "    daily_alert.loc['New Users',T_2] = len(set(df_T_2['Customer_mobile'])) - len(set(df_merged[(df_merged['Order_date']!=T_1) & (df_merged['Order_date']!=T_2)]['Customer_mobile']).intersection(set(df_T_2['Customer_mobile'])))\n",
    "    daily_alert.loc['Old Users',T_2] = len(set(df_merged[(df_merged['Order_date']!=T_1) & (df_merged['Order_date']!=T_2)]['Customer_mobile']).intersection(set(df_T_2['Customer_mobile'])))\n",
    "\n",
    "    daily_alert['%chg'] = daily_alert.pct_change(axis=1)[T_1].round(2)\n",
    "    Data_Exists_Daily = True\n",
    "  else:\n",
    "    Data_Exists_Daily = False\n",
    "    errors(e, 'Data_Doesnt_Exist_For_Daily_Comparison', 'Daily_Alert', 'voosh')\n",
    "except Exception as e:\n",
    "  errors(e, 'Daily_Values', 'Daily_Alert', 'voosh')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "executionInfo": {
     "elapsed": 300,
     "status": "ok",
     "timestamp": 1653907875357,
     "user": {
      "displayName": "Pallavi Krishna",
      "userId": "10169624835644536579"
     },
     "user_tz": -240
    },
    "id": "dV_JP1Di2L4f",
    "outputId": "71831d5b-ea81-4448-d99e-e0299c5cd982"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-43e49329-89af-450e-bbdf-4b2801e94a06\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2022-05-28</th>\n",
       "      <th>2022-05-29</th>\n",
       "      <th>%chg</th>\n",
       "      <th>Week 20</th>\n",
       "      <th>Week 21</th>\n",
       "      <th>%WChg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Total Orders</th>\n",
       "      <td>23</td>\n",
       "      <td>40</td>\n",
       "      <td>0.74</td>\n",
       "      <td>240.00</td>\n",
       "      <td>245.00</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gross Revenue $</th>\n",
       "      <td>3307.58</td>\n",
       "      <td>5941.4</td>\n",
       "      <td>0.80</td>\n",
       "      <td>46508.69</td>\n",
       "      <td>40075.09</td>\n",
       "      <td>-0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Discount $</th>\n",
       "      <td>1232.58</td>\n",
       "      <td>1813.4</td>\n",
       "      <td>0.47</td>\n",
       "      <td>11682.69</td>\n",
       "      <td>12598.09</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Net Revenue $</th>\n",
       "      <td>2075</td>\n",
       "      <td>4128</td>\n",
       "      <td>0.99</td>\n",
       "      <td>34826.00</td>\n",
       "      <td>27477.00</td>\n",
       "      <td>-0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Avg Delivery Time</th>\n",
       "      <td>15.63</td>\n",
       "      <td>12.36</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>15.15</td>\n",
       "      <td>14.01</td>\n",
       "      <td>-0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Avg Prep time</th>\n",
       "      <td>2.5</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3.99</td>\n",
       "      <td>3.25</td>\n",
       "      <td>-0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MFR%</th>\n",
       "      <td>100.0</td>\n",
       "      <td>97.5</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>96.67</td>\n",
       "      <td>94.69</td>\n",
       "      <td>-0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New Users</th>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>1.10</td>\n",
       "      <td>107.00</td>\n",
       "      <td>106.00</td>\n",
       "      <td>-0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Old Users</th>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>0.33</td>\n",
       "      <td>62.00</td>\n",
       "      <td>68.00</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total Users</th>\n",
       "      <td>22</td>\n",
       "      <td>37</td>\n",
       "      <td>0.68</td>\n",
       "      <td>169.00</td>\n",
       "      <td>174.00</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-43e49329-89af-450e-bbdf-4b2801e94a06')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-43e49329-89af-450e-bbdf-4b2801e94a06 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-43e49329-89af-450e-bbdf-4b2801e94a06');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                  2022-05-28 2022-05-29  %chg   Week 20   Week 21  %WChg\n",
       "Total Orders              23         40  0.74    240.00    245.00   0.02\n",
       "Gross Revenue $      3307.58     5941.4  0.80  46508.69  40075.09  -0.14\n",
       "Discount $           1232.58     1813.4  0.47  11682.69  12598.09   0.08\n",
       "Net Revenue $           2075       4128  0.99  34826.00  27477.00  -0.21\n",
       "Avg Delivery Time      15.63      12.36 -0.21     15.15     14.01  -0.08\n",
       "Avg Prep time            2.5       2.76  0.10      3.99      3.25  -0.19\n",
       "MFR%                   100.0       97.5 -0.03     96.67     94.69  -0.02\n",
       "New Users                 10         21  1.10    107.00    106.00  -0.01\n",
       "Old Users                 12         16  0.33     62.00     68.00   0.10\n",
       "Total Users               22         37  0.68    169.00    174.00   0.03"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#daily_alert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATE WEEKLY MONTHLY AND DAILY ALERTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-8AsYHWZ4o_l"
   },
   "outputs": [],
   "source": [
    "#Is_Week_Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 279,
     "status": "ok",
     "timestamp": 1653907825755,
     "user": {
      "displayName": "Pallavi Krishna",
      "userId": "10169624835644536579"
     },
     "user_tz": -240
    },
    "id": "FTCSBUYwOy5L"
   },
   "outputs": [],
   "source": [
    "#if Is_Week_Start:\n",
    "#week_1 = T_Date.week -1 # to be commented, test purpose\n",
    "#week_2 = T_Date.week -2 # to be commented, test purpose\n",
    "#if 1==1: # to be commented, test purpose\n",
    "try:\n",
    "\n",
    "  if Is_Week_Start:\n",
    "  #  daily_alert[['Last Week W-1','W-2']] = 0.0\n",
    "    df_W_1 = df_merged[df_merged['Week']==week_1]\n",
    "    df_W_2 = df_merged[df_merged['Week']==week_2]\n",
    "  #  print(len(df_W_1),len(df_W_2))\n",
    "\n",
    "    if (len(df_W_1) !=0 and len(df_W_2) !=0):\n",
    "\n",
    "      #Prepare T-2 Alert\n",
    "      daily_alert.loc['Total Orders',('Week ' + str(week_2))] = round(len(df_W_2),0)\n",
    "      daily_alert.loc['Gross Revenue $',('Week ' + str(week_2))] = df_W_2['Revenue'].sum() + df_W_2['Total_discount'].sum()\n",
    "      daily_alert.loc['Discount $',('Week ' + str(week_2))] = df_W_2['Total_discount'].sum()\n",
    "      daily_alert.loc['Net Revenue $',('Week ' + str(week_2))] = df_W_2['Revenue'].sum()\n",
    "      daily_alert.loc['Avg Delivery Time',('Week ' + str(week_2))] = round(df_W_2[df_W_2['makeline_Delivery_final']<=100]['makeline_Delivery_final'].mean(),2)\n",
    "      daily_alert.loc['Avg Prep time',('Week ' + str(week_2))] = round(df_W_2[df_W_2['Prep_Time']!=0]['Prep_Time'].mean(),2)\n",
    "      daily_alert.loc['MFR%',('Week ' + str(week_2))] = round((len(df_W_2[~df_W_2['MFR_Marked']])/len(df_W_2))*100,2)\n",
    "      daily_alert.loc['Total Users',('Week ' + str(week_2))] = int(round(len(set(df_W_2['Customer_mobile'])),0))\n",
    "      daily_alert.loc['New Users',('Week ' + str(week_2))] = int(round(len(set(df_W_2['Customer_mobile'])) - len(set(df_merged[(df_merged['Week']!=week_1) & (df_merged['Week']!=week_2)]['Customer_mobile']).intersection(set(df_W_2['Customer_mobile']))),0))\n",
    "      daily_alert.loc['Old Users',('Week ' + str(week_2))] = int(round(len(set(df_merged[(df_merged['Week']!=week_1) & (df_merged['Week']!=week_2)]['Customer_mobile']).intersection(set(df_W_2['Customer_mobile']))),0))\n",
    "\n",
    "      #Prepare W-1 Alert\n",
    "      daily_alert.loc['Total Orders',('Week ' + str(week_1))] = round(len(df_W_1),0)\n",
    "      daily_alert.loc['Gross Revenue $',('Week ' + str(week_1))] = df_W_1['Revenue'].sum() + df_W_1['Total_discount'].sum()\n",
    "      daily_alert.loc['Discount $',('Week ' + str(week_1))] = df_W_1['Total_discount'].sum()\n",
    "      daily_alert.loc['Net Revenue $',('Week ' + str(week_1))] = df_W_1['Revenue'].sum()\n",
    "      daily_alert.loc['Avg Delivery Time',('Week ' + str(week_1))] = round(df_W_1[df_W_1['makeline_Delivery_final']<=100]['makeline_Delivery_final'].mean(),2)\n",
    "      daily_alert.loc['Avg Prep time',('Week ' + str(week_1))] = round(df_W_1[df_W_1['Prep_Time']!=0]['Prep_Time'].mean(),2)\n",
    "      daily_alert.loc['MFR%',('Week ' + str(week_1))] = round((len(df_W_1[~df_W_1['MFR_Marked']])/len(df_W_1))*100,2)\n",
    "      daily_alert.loc['Total Users',('Week ' + str(week_1))] = len(set(df_W_1['Customer_mobile']))\n",
    "      daily_alert.loc['New Users',('Week ' + str(week_1))] = len(set(df_W_1['Customer_mobile'])) - len(set(df_merged[df_merged['Week']!=week_1]['Customer_mobile']).intersection(set(df_W_1['Customer_mobile'])))\n",
    "      daily_alert.loc['Old Users',('Week ' + str(week_1))] = len(set(df_merged[df_merged['Week']!=week_1]['Customer_mobile']).intersection(set(df_W_1['Customer_mobile'])))\n",
    "\n",
    "      daily_alert['%WChg'] = daily_alert[[('Week ' + str(week_2)),('Week ' + str(week_1))]].pct_change(axis=1)[('Week ' + str(week_1))].round(2).fillna(0)\n",
    "      Data_Exists_Weekly = True\n",
    "\n",
    "    else:\n",
    "      Data_Exists_Weekly = False\n",
    "      errors(e, 'Data_Doesnt_Exist_For_Weekly_Comparison', 'Daily_Alert', 'voosh')\n",
    "except Exception as e:\n",
    "  errors(e, 'Weekly_Values', 'Daily_Alert', 'voosh')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3gfP9iCGuc48"
   },
   "outputs": [],
   "source": [
    "#Monthly Alert\n",
    "\n",
    "#month_1=5 # to be commented\n",
    "#month_2=4 # to be commented\n",
    "#if 1==1: # to be commented\n",
    "try:\n",
    "\n",
    "  if Is_Month_Start:\n",
    "\n",
    "  #  daily_alert[['Last Week W-1','W-2']] = 0.0\n",
    "    df_M_1 = df_merged[df_merged['Month']==month_1]\n",
    "    df_M_2 = df_merged[df_merged['Month']==month_2]\n",
    "  #  print(len(df_M_1),len(df_M_2))\n",
    "\n",
    "    if (len(df_M_1) !=0 and len(df_M_2) !=0):\n",
    "      #Prepare M-2 Alert\n",
    "      daily_alert.loc['Total Orders',('Month ' + str(month_2))] = len(df_M_2)\n",
    "      daily_alert.loc['Gross Revenue $',('Month ' + str(month_2))] = df_M_2['Revenue'].sum() + df_M_2['Total_discount'].sum()\n",
    "      daily_alert.loc['Discount $',('Month ' + str(month_2))] = df_M_2['Total_discount'].sum()\n",
    "      daily_alert.loc['Net Revenue $',('Month ' + str(month_2))] = df_M_2['Revenue'].sum()\n",
    "      daily_alert.loc['Avg Delivery Time',('Month ' + str(month_2))] = round(df_M_2[df_M_2['makeline_Delivery_final']<=100]['makeline_Delivery_final'].mean(),2)\n",
    "      daily_alert.loc['Avg Prep time',('Month ' + str(month_2))] = round(df_M_2[df_M_2['Prep_Time']!=0]['Prep_Time'].mean(),2)\n",
    "      daily_alert.loc['MFR%',('Month ' + str(month_2))] = round((len(df_M_2[~df_M_2['MFR_Marked']])/len(df_M_2)*100),2)\n",
    "      daily_alert.loc['Total Users',('Month ' + str(month_2))] = len(set(df_M_2['Customer_mobile']))\n",
    "      daily_alert.loc['New Users',('Month ' + str(month_2))] = int(round(len(set(df_M_2['Customer_mobile'])) - len(set(df_merged[(df_merged['Month']!=month_1) & (df_merged['Month']!=month_2)]['Customer_mobile']).intersection(set(df_M_2['Customer_mobile']))),0))\n",
    "      daily_alert.loc['Old Users',('Month ' + str(month_2))] = int(round(len(set(df_merged[(df_merged['Month']!=month_1) & (df_merged['Month']!=month_2)]['Customer_mobile']).intersection(set(df_M_2['Customer_mobile']))),0))\n",
    "\n",
    "      #Prepare M-1 Alert\n",
    "      daily_alert.loc['Total Orders',('Month ' + str(month_1))] = len(df_M_1)\n",
    "      daily_alert.loc['Gross Revenue $',('Month ' + str(month_1))] = df_M_1['Revenue'].sum() + df_M_1['Total_discount'].sum()\n",
    "      daily_alert.loc['Discount $',('Month ' + str(month_1))] = df_M_1['Total_discount'].sum()\n",
    "      daily_alert.loc['Net Revenue $',('Month ' + str(month_1))] = df_M_1['Revenue'].sum()\n",
    "      daily_alert.loc['Avg Delivery Time',('Month ' + str(month_1))] = round(df_M_1[df_M_1['makeline_Delivery_final']<=100]['makeline_Delivery_final'].mean(),2)\n",
    "      daily_alert.loc['Avg Prep time',('Month ' + str(month_1))] = round(df_M_1[df_M_1['Prep_Time']!=0]['Prep_Time'].mean(),2)\n",
    "      daily_alert.loc['MFR%',('Month ' + str(month_1))] = round((len(df_M_1[~df_M_1['MFR_Marked']])/len(df_M_1))*100,2)\n",
    "      daily_alert.loc['Total Users',('Month ' + str(month_1))] = len(set(df_M_1['Customer_mobile']))\n",
    "      daily_alert.loc['New Users',('Month ' + str(month_1))] = len(set(df_M_1['Customer_mobile'])) - len(set(df_merged[df_merged['Month']!=month_1]['Customer_mobile']).intersection(set(df_M_1['Customer_mobile'])))\n",
    "      daily_alert.loc['Old Users',('Month ' + str(month_1))] = len(set(df_merged[df_merged['Month']!=month_1]['Customer_mobile']).intersection(set(df_M_1['Customer_mobile'])))\n",
    "\n",
    "      daily_alert['%MChg'] = daily_alert[[('Month ' + str(month_2)),('Month ' + str(month_1))]].pct_change(axis=1)[('Month ' + str(month_1))].round(2)\n",
    "      Data_Exists_Monthly = True\n",
    "\n",
    "    else:\n",
    "      Data_Exists_Monthly = False\n",
    "      errors(e, 'Data_Doesnt_Exist_For_Monthly_Comparison', 'Daily_Alert', 'voosh')\n",
    "except Exception as e:\n",
    "  errors(e, 'Monthly_Values', 'Daily_Alert', 'voosh')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_hOKMYu_Hlo-"
   },
   "outputs": [],
   "source": [
    "#daily_alert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yY7RGe1rHpW0"
   },
   "outputs": [],
   "source": [
    "# Change the decimals on Total Orders, New Users, Old Users, Total Users to 0\n",
    "try:\n",
    "\n",
    "  columns_change=[]\n",
    "  rows_change = ['Total Orders','New Users','Old Users','Total Users']\n",
    "  if Data_Exists_Daily: \n",
    "    columns_change.append(T_1)\n",
    "    columns_change.append(T_2)\n",
    "  if Data_Exists_Weekly:\n",
    "    columns_change.append('Week ' + str(week_1))\n",
    "    columns_change.append('Week ' + str(week_2)) \n",
    "  if Data_Exists_Monthly:\n",
    "    columns_change.append('Month '+str(month_1))\n",
    "    columns_change.append('Month ' +str(month_2)) \n",
    "\n",
    "  for row in rows_change:\n",
    "    for column in columns_change:\n",
    "      if pd.notna(daily_alert.loc[row,column]):\n",
    "        daily_alert.loc[row,column] = str(int(daily_alert.loc[row,column]))\n",
    "  \n",
    "  # Change Nans in the df into '-\n",
    "  daily_alert.fillna('-',inplace=True)\n",
    "\n",
    "except Exception as e:\n",
    "  errors(e, 'Format_Change', 'Daily_Alert', 'voosh')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATE WEEKLY MONTHLY AND DAILY CSV FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uBLS4mrdJisV"
   },
   "outputs": [],
   "source": [
    "#orders,gross,discount,revenue,avg_delivery,avg_prep,new_users,old_users = []\n",
    "# Daily CSV\n",
    "try:\n",
    "\n",
    "  if Data_Exists_Daily:\n",
    "\n",
    "    store_name = df_T_1['Outlet_name'].unique()\n",
    "    df_daily_csv_T1 =pd.DataFrame(columns=['Date','Total Orders','Gross Revenue $', 'Discount $','Net Revenue $', 'Avg Delivery Time',\n",
    "                                        'Avg Prep time', 'MFR%','New Users', 'Old Users', 'Total Users'], index=[store_name])\n",
    "    df_daily_csv_T2 =pd.DataFrame(columns=['Date','Total Orders','Gross Revenue $', 'Discount $','Net Revenue $', 'Avg Delivery Time',\n",
    "                                        'Avg Prep time', 'MFR%', 'New Users', 'Old Users','Total Users'], index=[store_name])\n",
    "\n",
    "    for i in store_name:\n",
    "      df = df_T_1[df_T_1['Outlet_name']==i]\n",
    "      df_daily_csv_T1.loc[i,'Date'] = T_1\n",
    "      df_daily_csv_T1.loc[i,'Total Orders'] = df['Order_id'].count()\n",
    "      df_daily_csv_T1.loc[i,'Net Revenue $'] = df['Revenue'].sum()\n",
    "      df_daily_csv_T1.loc[i,'Discount $'] = df['Total_discount'].sum()\n",
    "      df_daily_csv_T1.loc[i,'Gross Revenue $'] = float(df['Revenue'].sum() + df['Total_discount'].sum())\n",
    "\n",
    "      df_daily_csv_T1.loc[i,'Avg Delivery Time'] = round(df[df['makeline_Delivery_final']<=100]['makeline_Delivery_final'].mean(),2)\n",
    "      if (len(df) and len(df[~df['MFR_Marked']]) > 0):\n",
    "        df_daily_csv_T1.loc[i,'MFR%'] = round((len(df[~df['MFR_Marked']])/len(df))*100,2)\n",
    "      else:\n",
    "        df_daily_csv_T1.loc[i,'MFR%'] = 0\n",
    "      df_daily_csv_T1.loc[i,'Avg Prep time'] = round(df[df['Prep_Time']!=0]['Prep_Time'].mean(),2)\n",
    "      df_daily_csv_T1.loc[i,'New Users'] = len(set(df['Customer_mobile'])) - len(set(df_merged[df_merged['Order_date']!=T_1]['Customer_mobile']).intersection(set(df['Customer_mobile'])))\n",
    "      df_daily_csv_T1.loc[i,'Old Users'] = len(set(df_merged[df_merged['Order_date']!=T_1]['Customer_mobile']).intersection(set(df['Customer_mobile'])))\n",
    "      df_daily_csv_T1.loc[i,'Total Users'] = len(set(df['Customer_mobile']))\n",
    "\n",
    "    for i in store_name:\n",
    "      df = df_T_2[df_T_2['Outlet_name']==i]\n",
    "      df_daily_csv_T2.loc[i,'Date'] = T_2\n",
    "      df_daily_csv_T2.loc[i,'Total Orders'] = df['Order_id'].count()\n",
    "      df_daily_csv_T2.loc[i,'Net Revenue $'] = df['Revenue'].sum()\n",
    "      df_daily_csv_T2.loc[i,'Discount $'] = df['Total_discount'].sum()\n",
    "      df_daily_csv_T2.loc[i,'Gross Revenue $'] = float(df['Revenue'].sum() + df['Total_discount'].sum())\n",
    "\n",
    "      df_daily_csv_T2.loc[i,'Avg Delivery Time'] = round(df[df['makeline_Delivery_final']<=100]['makeline_Delivery_final'].mean(),2)\n",
    "      df_daily_csv_T2.loc[i,'Avg Prep time'] = round(df[df['Prep_Time']!=0]['Prep_Time'].mean(),2)\n",
    "      if (len(df) and len(df[~df['MFR_Marked']]) > 0):\n",
    "        df_daily_csv_T2.loc[i,'MFR%'] = round((len(df[~df['MFR_Marked']])/len(df)*100),2)\n",
    "      else:\n",
    "        df_daily_csv_T2.loc[i,'MFR%'] = 0\n",
    "      df_daily_csv_T2.loc[i,'Total Users'] = len(set(df['Customer_mobile']))\n",
    "    \n",
    "      df_daily_csv_T2.loc[i,'New Users'] = len(set(df['Customer_mobile'])) - len(set(df_merged[(df_merged['Order_date']!=T_1) & (df_merged['Order_date']!=T_2)]['Customer_mobile']).intersection(set(df['Customer_mobile'])))\n",
    "      df_daily_csv_T2.loc[i,'Old Users'] = len(set(df_merged[(df_merged['Order_date']!=T_1) & (df_merged['Order_date']!=T_2)]['Customer_mobile']).intersection(set(df['Customer_mobile'])))\n",
    "\n",
    "    #  daily_alert.loc['New Users','(T-2)'] = len(set(df_merged[df_merged['Order_date']!=T_1]['Customer_mobile']).intersection(set(df_T_1['Customer_mobile'])))\n",
    "    #  daily_alert.loc['Old Users','(T-2)'] = len(set(df_T_2['Customer_mobile']).difference(set(df_merged[(df_merged['Order_date']!=T_1)&(df_merged['Order_date']!=T_2)]['Customer_mobile'])))\n",
    "    df_daily_csv = pd.concat([df_daily_csv_T1,df_daily_csv_T2])\n",
    "    df_daily_csv.reset_index (inplace=True)\n",
    "    df_daily_csv.rename(columns = {'level_0':'Store Name'}, inplace = True)\n",
    "    df_daily_csv=df_daily_csv.sort_values(by=['Store Name'])\n",
    "\n",
    "except Exception as e:\n",
    "  errors(e, 'Daily_CSV', 'Daily_Alert', 'voosh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UReAiqj78z1Z"
   },
   "outputs": [],
   "source": [
    "#df_daily_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s-6dt7z_jSkD"
   },
   "outputs": [],
   "source": [
    "# weekly extract\n",
    "#orders,gross,discount,revenue,avg_delivery,avg_prep,new_users,old_users = []\n",
    "try:\n",
    "\n",
    "  if Data_Exists_Weekly:\n",
    "    store_name = df_W_1['Outlet_name'].unique()\n",
    "    df_daily_csv_W1 =pd.DataFrame(columns=['Week','Total Orders','Gross Revenue $', 'Discount $','Net Revenue $', 'Avg Delivery Time',\n",
    "                                        'Avg Prep time', 'MFR%', 'New Users', 'Old Users','Total Users'], index=[store_name])\n",
    "    df_daily_csv_W2 =pd.DataFrame(columns=['Week','Total Orders','Gross Revenue $', 'Discount $','Net Revenue $', 'Avg Delivery Time',\n",
    "                                        'Avg Prep time', 'MFR%', 'New Users', 'Old Users','Total Users'], index=[store_name])\n",
    "\n",
    "    for i in store_name:\n",
    "      df = df_W_1[df_W_1['Outlet_name']==i]\n",
    "      df_daily_csv_W1.loc[i,'Week'] = week_1\n",
    "      df_daily_csv_W1.loc[i,'Total Orders'] = df['Order_id'].count()\n",
    "      df_daily_csv_W1.loc[i,'Net Revenue $'] = df['Revenue'].sum()\n",
    "      df_daily_csv_W1.loc[i,'Discount $'] = df['Total_discount'].sum()\n",
    "      df_daily_csv_W1.loc[i,'Gross Revenue $'] = float(df['Revenue'].sum() + df['Total_discount'].sum())\n",
    "\n",
    "      df_daily_csv_W1.loc[i,'Avg Delivery Time'] = round(df[df['makeline_Delivery_final']<=100]['makeline_Delivery_final'].mean(),2)\n",
    "      df_daily_csv_W1.loc[i,'Avg Prep time'] = round(df[df['Prep_Time']!=0]['Prep_Time'].mean(),2)\n",
    "      if (len(df) and len(df[~df['MFR_Marked']]) > 0):\n",
    "        df_daily_csv_W1.loc[i,'MFR%'] = round((len(df[~df['MFR_Marked']])/len(df))*100,2)\n",
    "      else:\n",
    "        df_daily_csv_W1.loc[i,'MFR%'] = 0\n",
    "      df_daily_csv_W1.loc[i,'New Users'] = len(set(df['Customer_mobile'])) - len(set(df_merged[df_merged['Week']!=week_1]['Customer_mobile']).intersection(set(df['Customer_mobile'])))\n",
    "      df_daily_csv_W1.loc[i,'Old Users'] = len(set(df_merged[df_merged['Week']!=week_1]['Customer_mobile']).intersection(set(df['Customer_mobile'])))\n",
    "      df_daily_csv_W1.loc[i,'Total Users'] = len(set(df['Customer_mobile']))\n",
    "\n",
    "    #  df_daily_csv_T1.loc[i,'New Users'] = len(set(df['Customer_mobile'])) - len(set(df_merged[df_merged['Order_date']!=T_1]['Customer_mobile']).intersection(set(df['Customer_mobile'])))\n",
    "    #  df_daily_csv_T1.loc[i,'Old Users'] = len(set(df_merged[df_merged['Order_date']!=T_1]['Customer_mobile']).intersection(set(df['Customer_mobile'])))\n",
    "    #  df_daily_csv_T1.loc[i,'Total Users'] = len(set(df['Customer_mobile']))\n",
    "\n",
    "    for i in store_name:\n",
    "      df = df_W_2[df_W_2['Outlet_name']==i]\n",
    "      df_daily_csv_W2.loc[i,'Week'] = week_2\n",
    "      df_daily_csv_W2.loc[i,'Total Orders'] = df['Order_id'].count()\n",
    "      df_daily_csv_W2.loc[i,'Net Revenue $'] = df['Revenue'].sum()\n",
    "      df_daily_csv_W2.loc[i,'Discount $'] = df['Total_discount'].sum()\n",
    "      df_daily_csv_W2.loc[i,'Gross Revenue $'] = float(df['Revenue'].sum() + df['Total_discount'].sum())\n",
    "\n",
    "      df_daily_csv_W2.loc[i,'Avg Delivery Time'] = round(df[df['makeline_Delivery_final']<=100]['makeline_Delivery_final'].mean(),2)\n",
    "      df_daily_csv_W2.loc[i,'Avg Prep time'] = round(df[df['Prep_Time']!=0]['Prep_Time'].mean(),2)\n",
    "      if (len(df) and len(df[~df['MFR_Marked']]) > 0):\n",
    "        df_daily_csv_W2.loc[i,'MFR%'] = round((len(df[~df['MFR_Marked']])/len(df))*100,2)\n",
    "      else:\n",
    "        df_daily_csv_W2.loc[i,'MFR%'] = 0\n",
    "      \n",
    "      df_daily_csv_W2.loc[i,'Total Users'] = len(set(df['Customer_mobile']))\n",
    "    \n",
    "      df_daily_csv_W2.loc[i,'New Users'] = len(set(df['Customer_mobile'])) - len(set(df_merged[(df_merged['Week']!=week_1) & (df_merged['Week']!=week_2)]['Customer_mobile']).intersection(set(df['Customer_mobile'])))\n",
    "      df_daily_csv_W2.loc[i,'Old Users'] = len(set(df_merged[(df_merged['Week']!=week_1) & (df_merged['Week']!=week_2)]['Customer_mobile']).intersection(set(df['Customer_mobile'])))\n",
    "\n",
    "    #  daily_alert.loc['New Users','(T-2)'] = len(set(df_merged[df_merged['Order_date']!=T_1]['Customer_mobile']).intersection(set(df_T_1['Customer_mobile'])))\n",
    "    #  daily_alert.loc['Old Users','(T-2)'] = len(set(df_T_2['Customer_mobile']).difference(set(df_merged[(df_merged['Order_date']!=T_1)&(df_merged['Order_date']!=T_2)]['Customer_mobile'])))\n",
    "\n",
    "    df_daily_csv_w = pd.concat([df_daily_csv_W1,df_daily_csv_W2])\n",
    "    df_daily_csv_w.reset_index (inplace=True)\n",
    "    df_daily_csv_w.rename(columns = {'level_0':'Store Name'}, inplace = True)\n",
    "    df_daily_csv_w=df_daily_csv_w.sort_values(by=['Store Name'])\n",
    "\n",
    "except Exception as e:\n",
    "  errors(e, 'Weekly_CSV', 'Daily_Alert', 'voosh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TEhh6-gHLBSc"
   },
   "outputs": [],
   "source": [
    "#df_daily_csv_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7cO4KMaDFvM1"
   },
   "outputs": [],
   "source": [
    "# monthly extract\n",
    "#orders,gross,discount,revenue,avg_delivery,avg_prep,new_users,old_users = []\n",
    "try:\n",
    "\n",
    "  if Data_Exists_Monthly:\n",
    "\n",
    "    store_name = df_M_1['Outlet_name'].unique()\n",
    "    df_daily_csv_M1 =pd.DataFrame(columns=['Month','Total Orders','Gross Revenue $', 'Discount $','Net Revenue $', 'Avg Delivery Time',\n",
    "                                        'Avg Prep time', 'MFR%', 'New Users', 'Old Users'], index=[store_name])\n",
    "    df_daily_csv_M2 =pd.DataFrame(columns=['Month','Total Orders','Gross Revenue $', 'Discount $','Net Revenue $', 'Avg Delivery Time',\n",
    "                                        'Avg Prep time', 'MFR%', 'New Users', 'Old Users'], index=[store_name])\n",
    "\n",
    "    for i in store_name:\n",
    "      df = df_M_1[df_M_1['Outlet_name']==i]\n",
    "      df_daily_csv_M1.loc[i,'Month'] = month_1\n",
    "      df_daily_csv_M1.loc[i,'Total Orders'] = df['Order_id'].count()\n",
    "      df_daily_csv_M1.loc[i,'Net Revenue $'] = df['Revenue'].sum()\n",
    "      df_daily_csv_M1.loc[i,'Discount $'] = df['Total_discount'].sum()\n",
    "      df_daily_csv_M1.loc[i,'Gross Revenue $'] = float(df['Revenue'].sum() + df['Total_discount'].sum())\n",
    "\n",
    "      df_daily_csv_M1.loc[i,'Avg Delivery Time'] = round(df[df['makeline_Delivery_final']<=100]['makeline_Delivery_final'].mean(),2)\n",
    "      df_daily_csv_M1.loc[i,'Avg Prep time'] = round(df[df['Prep_Time']!=0]['Prep_Time'].mean(),2)\n",
    "      if (len(df) and len(df[~df['MFR_Marked']]) > 0):\n",
    "        df_daily_csv_M1.loc[i,'MFR%'] = round((len(df[~df['MFR_Marked']])/len(df))*100,2)\n",
    "      else:\n",
    "        df_daily_csv_W1.loc[i,'MFR%'] = 0\n",
    "      df_daily_csv_M1.loc[i,'New Users'] = len(set(df['Customer_mobile'])) - len(set(df_merged[df_merged['Month']!=month_1]['Customer_mobile']).intersection(set(df['Customer_mobile'])))\n",
    "      df_daily_csv_M1.loc[i,'Old Users'] = len(set(df_merged[df_merged['Month']!=month_1]['Customer_mobile']).intersection(set(df['Customer_mobile'])))\n",
    "      df_daily_csv_M1.loc[i,'Total Users'] = len(set(df['Customer_mobile']))\n",
    "      \n",
    "    #  df_daily_csv_M1.loc[i,'New Users'] = len(set(df_merged[df_merged['Order_date']!=T_1]['Customer_mobile']).intersection(set(df['Customer_mobile'])))\n",
    "    #  df_daily_csv_M1.loc[i,'Old Users'] = len(set(df['Customer_mobile']).difference(set(df_merged[(df_merged['Order_date']!=T_1)]['Customer_mobile'])))\n",
    "\n",
    "    for i in store_name:\n",
    "      df = df_M_2[df_M_2['Outlet_name']==i]\n",
    "      df_daily_csv_M2.loc[i,'Month'] = month_2\n",
    "      df_daily_csv_M2.loc[i,'Total Orders'] = df['Order_id'].count()\n",
    "      df_daily_csv_M2.loc[i,'Net Revenue $'] = df['Revenue'].sum()\n",
    "      df_daily_csv_M2.loc[i,'Discount $'] = df['Total_discount'].sum()\n",
    "      df_daily_csv_M2.loc[i,'Gross Revenue $'] = float(df['Revenue'].sum() + df['Total_discount'].sum())\n",
    "\n",
    "      df_daily_csv_M2.loc[i,'Avg Delivery Time'] = round(df[df['makeline_Delivery_final']<=100]['makeline_Delivery_final'].mean(),2)\n",
    "      df_daily_csv_M2.loc[i,'Avg Prep time'] = round(df[df['Prep_Time']!=0]['Prep_Time'].mean(),2)\n",
    "      if (len(df) and len(df[~df['MFR_Marked']]) > 0):\n",
    "        df_daily_csv_M2.loc[i,'MFR%'] = round((len(df[~df['MFR_Marked']])/len(df))*100,2)\n",
    "      else:\n",
    "        df_daily_csv_M2.loc[i,'MFR%'] = 0\n",
    "      df_daily_csv_M2.loc[i,'Total Users'] = len(set(df['Customer_mobile']))\n",
    "    \n",
    "      df_daily_csv_M2.loc[i,'New Users'] = len(set(df['Customer_mobile'])) - len(set(df_merged[(df_merged['Month']!=month_1) & (df_merged['Month']!=month_2)]['Customer_mobile']).intersection(set(df['Customer_mobile'])))\n",
    "      df_daily_csv_M2.loc[i,'Old Users'] = len(set(df_merged[(df_merged['Month']!=month_1) & (df_merged['Month']!=month_2)]['Customer_mobile']).intersection(set(df['Customer_mobile'])))\n",
    "      \n",
    "    #  df_daily_csv_M2.loc[i,'New Users'] = len(set(df_merged[df_merged['Order_date']!=T_1]['Customer_mobile']).intersection(set(df['Customer_mobile'])))\n",
    "    #  df_daily_csv_M2.loc[i,'Old Users'] = len(set(df['Customer_mobile']).difference(set(df_merged[(df_merged['Order_date']!=T_1)&(df_merged['Order_date']!=T_2)]['Customer_mobile'])))\n",
    "\n",
    "    #  daily_alert.loc['New Users','(T-2)'] = len(set(df_merged[df_merged['Order_date']!=T_1]['Customer_mobile']).intersection(set(df_T_1['Customer_mobile'])))\n",
    "    #  daily_alert.loc['Old Users','(T-2)'] = len(set(df_T_2['Customer_mobile']).difference(set(df_merged[(df_merged['Order_date']!=T_1)&(df_merged['Order_date']!=T_2)]['Customer_mobile'])))\n",
    "\n",
    "    df_daily_csv_m = pd.concat([df_daily_csv_M1,df_daily_csv_M2])\n",
    "    df_daily_csv_m.reset_index (inplace=True)\n",
    "    df_daily_csv_m.rename(columns = {'level_0':'Store Name'}, inplace = True)\n",
    "    df_daily_csv_m=df_daily_csv_m.sort_values(by=['Store Name'])\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "  errors(e, 'Monthly_CSV', 'Daily_Alert', 'voosh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r7WXTzFxNd7k"
   },
   "outputs": [],
   "source": [
    "#df_daily_csv_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dfiND4NxmN_G"
   },
   "outputs": [],
   "source": [
    "# Final Write into excel\n",
    "Created_excel = True\n",
    "try:\n",
    "  writer = ExcelWriter('Voosh_Alert.xlsx')\n",
    "  if Data_Exists_Daily:\n",
    "    df_daily_csv.to_excel(writer,'Daily by Store',index=True)\n",
    "  if Data_Exists_Weekly:\n",
    "    df_daily_csv_w.to_excel(writer,'Weekly by Store',index=True)\n",
    "  if Data_Exists_Monthly:\n",
    "    df_daily_csv_m.to_excel(writer,'Monthly by Store',index=True)\n",
    "  writer.save()\n",
    "\n",
    "except Exception as e:\n",
    "  errors(e, 'Write_CSV', 'Daily_Alert', 'voosh')\n",
    "  Created_excel = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FORMAT AND SEND EMAIL ALERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9hHNM_iC55yi"
   },
   "outputs": [],
   "source": [
    "#Data_Exists_Daily = False #test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 902,
     "status": "ok",
     "timestamp": 1652882849595,
     "user": {
      "displayName": "Pallavi Krishna",
      "userId": "10169624835644536579"
     },
     "user_tz": -240
    },
    "id": "tei1ObixGhNZ",
    "outputId": "cc1fa223-7ae5-4775-99e7-3eebb1073f75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '180d77ebd073dddf', 'threadId': '180d77ebd073dddf', 'labelIds': ['SENT']}\n"
     ]
    }
   ],
   "source": [
    "#from pandas.core.dtypes.base import E\n",
    "scope_1 = ['https://mail.google.com/']\n",
    "def gmail_authenticate():\n",
    "  creds = None\n",
    "  # the file token.pickle stores the user's access and refresh tokens, and is\n",
    "  # created automatically when the authorization flow completes for the first time\n",
    "  if os.path.exists(\"/content/token.pickle\"):\n",
    "      with open(\"/content/token.pickle\", \"rb\") as token:\n",
    "          creds = pickle.load(token)\n",
    "  # if there are no (valid) credentials availablle, let the user log in.\n",
    "  if not creds or not creds.valid:\n",
    "      if creds and creds.expired and creds.refresh_token:\n",
    "          creds.refresh(Request())\n",
    "      else:\n",
    "          flow = InstalledAppFlow.from_client_secrets_file(\n",
    "              '/content/gmail_creds.json', scope_1)\n",
    "          creds = flow.run_local_server(port=0)\n",
    "      # save the credentials for the next run\n",
    "      with open(\"/content/token.pickle\", \"wb\") as token:\n",
    "          pickle.dump(creds, token)\n",
    "  return build('gmail', 'v1', credentials=creds)\n",
    "try:\n",
    "\n",
    "  if Data_Exists_Daily: # send mail alert\n",
    "    service = gmail_authenticate()\n",
    "    html = \"\"\"<html>\n",
    "        <head></head>\n",
    "        <body>\n",
    "        <head>Hello Team,</head>\n",
    "        <br>\n",
    "        \n",
    "        This is an Overview and Comparison of performace for Yesterday (T-1) Vs Day Before Yesterday (T-2). Similary for Week & Month.\n",
    "        The overall table consists of various metrics whose comparisons are displayed below.\n",
    "        Also attached is the storewise breakdown of these metrics for the relevant periods.\n",
    "\n",
    "        <p>Report Generated Date: {}</p>\n",
    "        \n",
    "        \n",
    "        {}\n",
    "        <p> </p>\n",
    "        <p> </p>\n",
    "        \n",
    "        \n",
    "        <p>Thanks & regards,</p>\n",
    "        <p>Voosh DS Team</p>\n",
    "        </body>\n",
    "        <html>\"\"\".format(date.today().strftime(\"%Y-%m-%d\"), daily_alert.to_html(index=True),\n",
    "                      )  # changes\n",
    "\n",
    "    mimeMessage = MIMEMultipart()\n",
    "\n",
    "    # to_reciepents = ['sachin@voosh.in','jagruthi@voosh.in','sumit@voosh.in']\n",
    "    # cc_reciepents = ['kshitiz@voosh.in', 'akshat@voosh.in', 'gaurav@voosh.in', 'priyam@voosh.in','bilal@voosh.in','Radhika@voosh.in','srishti@voosh.in','sumit.c@voosh.in', \"zuber@voosh.in\"]\n",
    "    # to_reciepents = ['debidutta@voosh.in', 'iyyappan@voosh.in']\n",
    "    to_reciepents = ['pallavi@voosh.in']\n",
    "    cc_reciepents = ['pallavi@voosh.in']\n",
    "    #     cc_reciepents = [ 'iyyappan@voosh.in', 'roopansh@voosh.in', 'pranit@voosh.in', 'jakir@voosh.in', 'pallavi@voosh.in']\n",
    "    mimeMessage['to'] = \", \".join(to_reciepents)\n",
    "    mimeMessage['cc'] = \", \".join(cc_reciepents)\n",
    "\n",
    "    # send today's date as str\n",
    "    mimeMessage['subject'] = \"Daily email Alert for Voosh -  %s\" % (T_1)\n",
    "    mimeMessage.attach(MIMEText(html, 'html'))\n",
    "    if Created_excel:\n",
    "      part = MIMEBase('application', \"octet-stream\")\n",
    "      part.set_payload(open('Voosh_Alert.xlsx', \"rb\").read())\n",
    "      encoders.encode_base64(part)\n",
    "      part.add_header('Content-Disposition',\n",
    "      'attachment; filename=\"Voosh_Alert.xlsx\"')\n",
    "      mimeMessage.attach(part)\n",
    "    else:\n",
    "      print('Excel not attached')\n",
    "    raw_string = base64.urlsafe_b64encode(mimeMessage.as_bytes()).decode()\n",
    "    message = service.users().messages().send(\n",
    "    userId='me', body={'raw': raw_string}).execute()\n",
    "    print(message)\n",
    "\n",
    "  else:    #data not created daily - if Data_Exists_Daily: # send mail alert\n",
    "    service = gmail_authenticate()\n",
    "    html = \"\"\"<html>\n",
    "        <head></head>\n",
    "        <body>\n",
    "        <head>Hello Team,</head>\n",
    "        <br>\n",
    "        \n",
    "        Data was not found for T-1 / T-2 days and hence alert was not created. Please re-run after data upload\n",
    "        to send the alert. \n",
    "\n",
    "        <p>Report Not Generated for : {}</p>\n",
    "        \n",
    "        \n",
    "        <p> </p>\n",
    "        <p> </p>\n",
    "        \n",
    "        \n",
    "        <p>Thanks & regards,</p>\n",
    "        <p>Voosh DS Team</p>\n",
    "        </body>\n",
    "        <html>\"\"\".format(date.today().strftime(\"%Y-%m-%d\"))\n",
    "                        \n",
    "                        \n",
    "\n",
    "    mimeMessage = MIMEMultipart()\n",
    "\n",
    "    # to_reciepents = ['sachin@voosh.in','jagruthi@voosh.in','sumit@voosh.in']\n",
    "    # cc_reciepents = ['kshitiz@voosh.in', 'akshat@voosh.in', 'gaurav@voosh.in', 'priyam@voosh.in','bilal@voosh.in','Radhika@voosh.in','srishti@voosh.in','sumit.c@voosh.in', \"zuber@voosh.in\"]\n",
    "    # to_reciepents = ['debidutta@voosh.in', 'iyyappan@voosh.in']\n",
    "  #  to_reciepents = ['pallavi@voosh.in','pranit@voosh.in','jakir@voosh.in','iyyappan@voosh.in']\n",
    "    to_reciepents = ['pallavi@voosh.in']\n",
    "    cc_reciepents = ['pallavi@voosh.in']\n",
    "    #     cc_reciepents = [ 'iyyappan@voosh.in', 'roopansh@voosh.in', 'pranit@voosh.in', 'jakir@voosh.in', 'pallavi@voosh.in']\n",
    "    mimeMessage['to'] = \", \".join(to_reciepents)\n",
    "    mimeMessage['cc'] = \", \".join(cc_reciepents)\n",
    "\n",
    "    # send today's date as str\n",
    "    \n",
    "    mimeMessage['subject'] = \"Daily email Alert Not created for  -  %s\" % (T_1)\n",
    "    mimeMessage.attach(MIMEText(html, 'html'))\n",
    "    part = MIMEBase('application', \"octet-stream\")\n",
    "    raw_string = base64.urlsafe_b64encode(mimeMessage.as_bytes()).decode()\n",
    "    message = service.users().messages().send(\n",
    "    userId='me', body={'raw': raw_string}).execute()\n",
    "    print(message)\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "  errors(e, 'Send_mail', 'Daily_Alert', 'voosh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5yVtyGzd737z"
   },
   "outputs": [],
   "source": [
    "#daily_alert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_VpfKrixHDM2"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Store Health Alert.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
